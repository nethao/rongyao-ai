# 多采编同稿去重规则设计

> **实现状态**：已实现。采用 C 方案（duplicate_logs 表），不改动 submissions 表。重复稿件不抓取内容；新稿优于旧稿。

## 一、当前系统行为

### 现有去重逻辑
- **批次内**：同一批抓取的邮件中，按 `email_subject` 严格相等去重，重复主题跳过
- **数据库**：处理前查询 `email_subject`，已存在则直接跳过，不再创建投稿

### 存在的问题
当**多个采编发送同一篇稿件**（内容相同）时，可能使用**不同的邮件主题**：
- 采编 A：`投，时，凤翔区人社局，春风迎归人 人社暖民心`
- 采编 B：`合，时，凤翔区人社局，春风迎归人 人社暖民心`（合作优先）
- 采编 C：`投，荣，凤翔区人社局，春风迎归人 人社暖民心`（媒体不同）

当前按 `email_subject` 去重会认为三者都是**独立稿件**，全部入库，导致重复处理。

---

## 二、你提出的判断优先级

### 1. 媒体
- **不同媒体** → 视为**有效稿件**（同一内容投多媒体，各算一篇）
- **同一媒体** → 进入后续判断，可能为重复

### 2. 合作方式
- **合作（合）** 优先于 **投稿（投）**
- 同一媒体下：保留合作，淘汰投稿

### 3. 邮件时间
- 以上两点仍无法区分时（如均为合作或均为投稿）
- **先发的有效**，后发的为重复

### 4. 重复稿件的系统体现
- 需在系统中明确标识、展示重复稿件

---

## 三、核心问题：如何定义「同一篇稿件」

要在入库前做去重，需要先定义「同一篇」的判定键。

### 推荐方案：`来稿单位 + 标题` 作为稿件唯一键

| 维度   | 建议                             | 说明                         |
|--------|----------------------------------|------------------------------|
| 来稿单位 | `source_unit`                    | 邮件标题解析的第三段         |
| 标题   | `title`（或解析后的 display_title） | 第四段，或公众号/美篇抓取标题 |

**理由**：
- 同一单位、同一标题，可视为同一篇稿件
- 标题可能因抓取/改写略有差异，可考虑模糊匹配（见下）

**可选增强**：
1. **归一化**：`source_unit`、`title` 去除空格、全角转半角、统一大小写
2. **标题模糊**：Levenshtein 或包含关系（需设定阈值），防「春风迎归人 人社暖民心」vs「春风迎归人 人社暖民心 」

**建议先采用严格相等**：`(source_unit, title)` 完全一致即视为同稿，运行一段时间后再看是否需要模糊匹配。

---

## 四、去重流程（入库时）

```
新邮件 → 解析 (合作方式, 媒体, 来稿单位, 标题)
       → 查库：是否存在 (source_unit, title) 且 media_type 相同的记录？
       
       【否】→ 视为新稿，正常创建
       
       【是】→ 命中「同稿同媒体」：
              1. 对比合作方式：存在「合作」→ 保留合作稿，当前为投稿则标为重复
              2. 均为合作或均为投稿 → 按 email_date 比较，早的保留，晚的标为重复
```

### 伪代码

```python
# 同一稿件 = 相同 (source_unit, title)
# 同媒体重复 = 同一稿件 + 相同 media_type

candidates = 查询 media_type=X AND source_unit=S AND title=T 的投稿（含合作方式、邮件时间）

if not candidates:
    创建新投稿
else:
    # 按优先级排序：1.合作优先 2.邮件时间早优先
    sorted_cands = sorted(candidates, key=lambda x: (
        0 if x.cooperation_type == 'partner' else 1,  # 合作在前
        x.email_date or datetime.max  # 时间早在前
    ))
    winner = sorted_cands[0]
    if 当前邮件 优于 winner:
        # 当前是合作而 winner 是投稿，或当前更早
        将 winner 标为重复，当前创建为有效稿
    else:
        当前标为重复，不创建 或 创建但标记为重复
```

---

## 五、重复稿件在系统中的体现

### 方案 A：只标记，不落库（推荐）

**逻辑**：判定为重复时，**不创建投稿**，仅记一条日志，如  
`重复稿件，已跳过：合，时，凤翔区人社局，xxx（有效稿 ID=123）`  
- 实现简单
- 不影响统计、列表、数据分析
- 缺点：无法在系统中查看「曾被跳过的重复邮件」

### 方案 B：落库 + 标记为重复

**数据模型**：

```sql
ALTER TABLE submissions ADD COLUMN is_duplicate BOOLEAN DEFAULT FALSE;
ALTER TABLE submissions ADD COLUMN effective_submission_id INT REFERENCES submissions(id);
```

- `is_duplicate = true`：该记录为重复稿
- `effective_submission_id`：指向保留的有效稿件

**列表展示**：
- 默认过滤掉 `is_duplicate = true`，不参与统计
- 可提供「显示重复稿件」开关，以灰色/折叠方式展示，并显示「重复于 #123」

**优点**：可追溯、可审计、可核对去重结果  
**缺点**：表数据增多，需设计好查询和统计口径

### 方案 C：单独「去重记录」表

```sql
CREATE TABLE duplicate_logs (
  id INT PRIMARY KEY,
  email_subject VARCHAR(255),
  email_date DATETIME,
  skipped_reason VARCHAR(100),  -- 'duplicate_same_media'
  effective_submission_id INT
);
```

- `submissions` 表不变
- 重复稿件只写入 `duplicate_logs`
- 适合做审计、报表，对主流程影响小

---

## 六、实现建议

### 阶段一（最小改动）

1. **入库去重**：在 `process_email` 中，创建投稿前按 `(source_unit, title, media_type)` 查库
2. 若存在同稿同媒体：
   - 按「合作 > 投稿」再按 `email_date` 排序，判断当前邮件是否应替换已有稿
   - 若当前应淘汰：**不创建**，打日志
   - 若当前应替换：将原稿标为 `is_duplicate`（若采用方案 B），再创建新稿并作为有效稿
3. 先不落库重复记录，采用**方案 A**，快速上线

### 阶段二（可追溯）

1. 新增 `is_duplicate`、`effective_submission_id`
2. 或新增 `duplicate_logs` 表（方案 C）
3. 前端增加「重复稿件」筛选与展示

### 边界情况

| 场景                         | 处理建议                                   |
|------------------------------|--------------------------------------------|
| source_unit / title 解析失败 | 回退到原逻辑：仅按 `email_subject` 去重   |
| 标题来自公众号抓取，与原主题不一致 | 用抓取后的 `title` 作为稿件标识参与去重   |
| 多封邮件几乎同时到达         | 按 `email_date` 精度比较，精度相同时保留先入库的 |

---

## 七、待确认问题

1. **「同一篇」的严格程度**：是否接受 `(source_unit, title)` 严格相等？是否需要支持标题模糊匹配？
2. **重复记录是否落库**：仅日志（方案 A）还是需要可查（方案 B/C）？
3. **替换逻辑**：若新邮件优于已有稿（例如新为合作、旧为投稿），是否要**替换**（将旧稿标为重复，新稿作有效）？还是仅当没有有效稿时才创建？
4. **历史数据**：是否要对既有数据做一次批量去重？若做，规则是否与上述一致？

你可以先按当前理解实现一版，再根据实际使用情况迭代。
