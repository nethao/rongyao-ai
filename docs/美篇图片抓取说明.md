# 美篇图片抓取说明（历史与现状）

根据项目目录、文档及 Git 记录整理的**之前美篇图片是如何抓取的**，以及当前方案的差异。

---

## 一、之前的美篇图片抓取方式（Playwright 方案）

### 1. 来源与实现位置

- **首次实现**：Git commit `db098e90`（2026-02-15），`backend/app/services/web_fetcher.py`
- **文档**：`日报-2026-02-15.md`、`Playwright问题诊断与解决方案.md`

### 2. 抓取流程

1. **用 Playwright 渲染整页**
   - `async_playwright()` → `chromium.launch(headless=True)` → `page.goto(url, wait_until='networkidle', timeout=30000)`
   - `page.wait_for_timeout(2000)` 等待图片加载
   - `html_content = await page.content()` 拿到**前端渲染后的完整 DOM**

2. **定位正文容器**
   - 标题：`soup.find('div', {'class': 'caption-title-html'})`
   - 正文容器：`content_tag = soup.find('div', {'class': 'mp-article-tpl'})`
   - 在 `mp-article-tpl` 内保留完整 HTML 结构，用于**保留图文混排顺序**

3. **从正文容器内提取图片 URL**
   - 遍历：`content_tag.find_all('img')`
   - 属性优先级：`data-src` → `src` → `data-original` → `data-lazy-src`（任取其一）
   - 过滤：
     - 排除 `img_url.startswith('data:')`
     - 排除 URL 中含：`icon`、`avatar`、`badge`、`member`、`gift`、`logo`、`qrcode`、`code-logo`
   - URL 规范化：
     - `//` 开头 → 前加 `https:`
     - `/` 开头 → 前加 `https://www.meipian.cn`
     - 非 http 开头 → 前加 `https://www.meipian.cn/`
   - 去重后按出现顺序加入 `images` 列表

4. **保留原始 HTML**
   - `original_html = str(content_tag)`，即整段 `mp-article-tpl` 的 HTML
   - 下游用该 HTML 创建草稿，上传图片到 OSS 后**替换 HTML 中的图片 URL**，从而保留图文位置

### 3. 关键代码（历史片段，来自 Git）

```python
# 提取正文（使用 mp-article-tpl 容器）
content_tag = soup.find('div', {'class': 'mp-article-tpl'})
# ...
# 提取图片 URL
images = []
img_attrs = ['data-src', 'src', 'data-original', 'data-lazy-src']
for img in content_tag.find_all('img'):
    img_url = None
    for attr in img_attrs:
        img_url = img.get(attr)
        if img_url:
            break
    if img_url and not img_url.startswith('data:'):
        # 过滤 icon/avatar/... 并规范化 URL
        if img_url not in images:
            images.append(img_url)
# 保存 HTML（保持图文排版）
original_html = str(content_tag)
return title, content_text, images, original_html
```

### 4. 文档中的说明

- **日报-2026-02-15.md**  
  - 使用 `mp-article-tpl` 容器保留完整 HTML；从 HTML 中**按顺序**提取图片和文本；上传图片到 OSS 后替换 HTML 中的图片 URL；草稿直接使用原始 HTML。  
  - 测试结果：投稿 46（美篇）6,004 字符 HTML，**2 张图片**，图文混排正确。

- **PRODUCTION_ISSUES.md / Playwright 文档**  
  - 美篇内容需要 JavaScript 渲染，使用 Playwright 抓取；Docker 中未安装浏览器会导致“美篇邮件抓取失败 / 手动发布美篇链接时报错”。

---

## 二、当前方案与差异

### 1. 当前逻辑（web_fetcher.py）

- **优先**：`_fetch_meipian_with_requests()`  
  - 用 requests 取首屏 HTML，解析** SEO 用**的 `<article>` → `<section>`。  
  - section 内为**转义后的 HTML**（如 `&lt;p class="ql-block"&gt;...`），unescape 后得到正文 HTML 再解析。  
  - 在该解析结果里同样会 `find_all("img")`，并按 `data-src` / `src` / `data-original` 取 URL、过滤、规范化。

- **差异**：  
  - 美篇**首屏 SEO 块**里多数文章**没有或很少 `<img>`**（正文/图多为前端 JS 渲染进 `mp-article-tpl`），所以**仅用 requests 时经常拿到 0 张图**。  
  - 之前能拿到图，是因为 **Playwright 拿到的是渲染后的 DOM**，其中 `mp-article-tpl` 内已有带 `data-src`/`src` 等的 `<img>`。

### 2. 若需恢复“带图”抓取

- **思路一**：在环境允许时启用 Playwright（如在 Docker 中按《Playwright问题诊断与解决方案》安装 Chromium），让现有**兜底**的 Playwright 分支能跑通，则仍从 `mp-article-tpl` 内按 `data-src` → `src` → `data-original` → `data-lazy-src` 顺序取图，逻辑与历史一致。  
- **思路二**：若美篇有公开的接口或首屏 JSON 内嵌了图片 URL，可在 requests 方案中额外解析该数据源，再合并进当前 `images` 列表与正文顺序（需针对美篇页面结构再做一次排查）。

---

## 三、相关文件与引用

| 文件 | 说明 |
|------|------|
| `backend/app/services/web_fetcher.py` | 美篇抓取入口；requests 优先，Crawl4AI/Playwright 兜底；图片从对应 DOM/媒体结果中按上述属性提取 |
| `backend/app/tasks/email_tasks.py` | 美篇来源时调用 `fetcher.fetch_meipian_article()`，用返回的 `image_urls` 上传 OSS，并用 `original_html` 参与草稿 |
| `backend/app/api/submissions.py` | 手动发稿选美篇时调用 `fetch_meipian_article_async()`，同样用返回的图片 URL 做预览上传 |
| `日报-2026-02-15.md` | 美篇图文混排、`mp-article-tpl`、2 张图测试记录 |
| `Playwright问题诊断与解决方案.md` | Playwright 在 Docker 中的问题与 Crawl4AI/requests 方案说明 |

---

**结论**：之前美篇图片是**在 Playwright 渲染后的页面中，从 `mp-article-tpl` 容器内的 `<img>` 上按 `data-src`、`src`、`data-original`、`data-lazy-src` 顺序取 URL，过滤并规范化后得到**；同时保留该段 HTML 作为 `original_html`，用于保留图文顺序。

---

## 四、当前方案：正文 + 补图 + 上传 OSS（已实现）

1. **先 requests**：解析首屏 SEO 的 `<article>`，得到标题和正文；多数文章此处无图。
2. **无图时补抓**：若图片列表为空，再调 **Playwright**（`_fetch_meipian_playwright_only`）打开页面，从 `mp-article-tpl` 内按上述属性提取图片 URL 和 `original_html`，与 requests 的标题/正文合并返回。
3. **下游**：`email_tasks` / 手动发稿 API 用返回的 `image_urls` 逐张 `download_image()` 并上传 OSS，再写投稿与草稿（含 `media_map` / `original_html`）。

**使 Playwright 在容器内可用（才能补图）**：

- **方式 A（推荐）**：在 backend 与 celery_worker 容器内各执行一次（代码挂载时一次即可，两容器共享 `./backend` 时 backend 安装后 Worker 可用）：
  ```bash
  docker exec rongyao-ai_backend_1 python -m playwright install chromium
  docker exec rongyao-ai_celery_worker_1 python -m playwright install chromium
  ```
  若 Worker 内安装到了 `/root/.cache`，需让运行进程能访问浏览器，例如：
  ```bash
  docker exec rongyao-ai_celery_worker_1 cp -r /root/.cache/ms-playwright/* /app/.cache/ms-playwright/
  docker exec rongyao-ai_celery_worker_1 chown -R appuser:appuser /app/.cache/ms-playwright
  ```
- **方式 B**：在 Dockerfile 中 `USER appuser` 之后增加 `RUN python -m playwright install chromium`，重建镜像后两服务均自带 Chromium（参见 `Playwright问题诊断与解决方案.md` 方案 A）。
